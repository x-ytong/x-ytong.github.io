<!DOCTYPE html>
<html lang="en">
<head>
	<meta charset="UTF-8">
	<title>Five-Billion-Pixels Dataset</title>
	<link type="text/css" href="/project/head/system.css" rel="stylesheet"/>
	<link type="text/css" href="/project/head/custom.css" rel="stylesheet"/>
	<script type="text/javascript" src="/project/head/custom.js"></script>
</head>

<body marginheight="0">
<div align="center"><h1>Enabling Country-Scale Land Cover Mapping with <br> Meter-Resolution Satellite Imagery</h1></div>

<p style="text-align: center">Xin-Yi Tong, Gui-Song Xia, Xiao Xiang Zhu</p>


<div style="border: 12px solid #FFFFFF"></div>
<p style="font-size: 12px; color: orange; text-align: center">The <b>Five-Billion-Pixels</b> dataset is released!</p>
<p style="font-size: 12px; color: orange; text-align: center">The coordinate information of <b>Five-Billion-Pixels</b> is now available!</p>
<p style="font-size: 12px; color: orange; text-align: center">The test data for land cover mapping is released!</p>
<p style="font-size: 12px; color: orange; text-align: center">The code and model for land cover mapping is now available!</p>


<h2>Introduction</h2>
<p>High-resolution satellite images can provide abundant, detailed spatial information for land cover classification, which is particularly 
important for studying the complicated built environment. However, due to the complex land cover patterns, the costly training sample collections, 
and the severe distribution shifts of satellite imageries caused by, e.g., geographical differences or acquisition conditions, few studies have 
applied high-resolution images to land cover mapping in detailed categories at large scale. To fill this gap, we present a large-scale land cover 
dataset, <b>Five-Billion-Pixels</b>. It contains more than 5 billion labeled pixels of 150 high-resolution Gaofen-2 (4 m) satellite images, 
annotated in a 24-category system covering <b>artificial-constructed</b>, <b>agricultural</b>, and <b>natural</b> classes. In addition, we propose 
a deep-learning-based unsupervised domain adaptation approach that can transfer classification models trained on labeled dataset (referred to as 
the source domain) to unlabeled data (referred to as the target domain) for large-scale land cover mapping. Specifically, we introduce an end-to-end 
Siamese network employing dynamic pseudo-label assignment and class balancing strategy to perform adaptive domain joint learning. To validate the 
generalizability of our dataset and the proposed approach across different sensors and different geographical regions, we carry out land cover 
mapping on five megacities in China and six cities in other five Asian countries severally using: PlanetScope (3 m), Gaofen-1 (8 m), and 
Sentinel-2 (10 m) satellite images. Over a total study area of 60,000 square kilometers, the experiments show promising results even though the 
input images are entirely unlabeled. The proposed approach, trained with the <b>Five-Billion-Pixels</b> dataset, enables high-quality and detailed 
land cover mapping across the whole country of China and some other Asian countries at meter-resolution.</p>
<div style="border: 4px solid #FFFFFF"></div>

<h3>Five-Billion-Pixels</h3>
<p>We present a large-scale land cover classification dataset, <b>Five-Billion-Pixels</b>. It has a spatial resolution of <b>4 m</b>, covers areas 
more than <b>50,000 square kilometers</b> in China, and contains more than <b>5 billion</b> labeled pixels. It possesses the advantage of rich 
categories, large coverage, wide distribution, and high-spatial resolution, which well reflects the distributions of real-world ground objects and 
can benefit to different land cover related studies.</p>

<div style="border: 9px solid #FFFFFF"></div>
<div id = "tab1" class = "tabMenu">
	<ul>
	<li class="on"><h4>Distribution and Categories</h4></li>
        <li class="off"><h4>Annotation Details</h4></li>
        <li class="off"><h4>Download</h4></li>
        </ul>
	<div id="firstPage" class="show">
	<img src="/figure/GID24/GID24example.png" width="800px">
        </div>
        <div id="secondPage" class= "hide">
	<p style="margin-top: 7px"><b>Five-Billion-Pixels</b> extends <a href="https://x-ytong.github.io/project/GID.html"><b>GID</b></a> 
	and <a href="https://captain-whu.github.io/HPS-Net/"><b>GID-15</b></a>. Miscellaneous or unclear areas that are extremely difficult 
	to annotate are considered as unlabeled. The categories of labeled pixels are double-checked and ensured to be correct.</p>
        <img src="/figure/GID24/GID24detail.png" width="800px">
        </div>
        <div id="thirdPage" class = "hide">
        <p style="margin-top: 7px">The <b>Five-Billion-Pixels</b> dataset is released under the open source license:</p>
        <li style="margin-top: 9px" class = "dot"><span class = "lin">Link: <a href="https://whueducn-my.sharepoint.com/:f:/g/personal/xinyi_tong_whu_edu_cn/Et46sPlc1UpPtAa5Sz22ksABy53By3PuWdS5UzkZ9zi68w?e=PlhrqQ"><b>Onedrive</b></a> (attention: OneDrive has a maximum download limit of 20GB for .zip files, please consider using the OneDrive client to synchronize the data, or download the data in separate folders or batches)</span></li>
        <li style="margin-top: 6px" class = "dot"><span class = "lin">Link: <a href="https://pan.baidu.com/s/1AJMHUwk53pG9iv-9Lx-gNA"><b>Baidudrive</b></a> (only available in China region, extraction code: FBPS)</span></li>
	<p style="margin-top: 11px">It can be easily modified to extract specific categories according to the purpose of the application, for example,
	by merging categories or setting unwanted categories as background.</p>
	</div>
</div>
<div style="border: 8px solid #FFFFFF"></div>
		
<h3>Land Cover Mapping</h3>
<p>We propose an unsupervised domain adaptation approach for practical large-scale land cover mapping. Concretely, we introduce an end-to-end 
Siamese network consisting of two branches, which separately process images from the source and target domain. In the target domain branch, image 
pixels with high-confidence are assigned with pseudo-labels and then utilized for domain joint learning with the source domain branch. To mitigate 
negative adaptation, we adopt dynamic pseudo-label assignment and class balancing strategy in the network. Based on the proposed approach, we carry 
out land cover mapping on five megacities in China and six cities in other five Asian countries severally using unlabeled <b>PlanetScope (PS)</b>, 
<b>Gaofen-1 (GF-1)</b>, and <b>Sentinel-2 (ST-2)</b> satellite images. The encouraging results show the generality of our dataset and approach 
across different satellites and regions.</p>

<div style="border: 9px solid #FFFFFF"></div>
<div id = "tab2" class = "tabMenu">
	<ul>
	<li class="on"><h4>Overview of Approach</h4></li>
        <li class="off"><h4>Study Areas</h4></li>
        <li class="off"><h4>Code and Data</h4></li>
        </ul>
	<div id="firstPage" class="show">
	<table align="center"><tr>
	<td><img src="/figure/GID24/GID24siamesenetwork.png" style="height:188.6px"></td>
	<td><img src="/figure/GID24/GID24pseudolabel.png" style="height:188.6px"></td>
	</tr></table>
        </div>
        <div id="secondPage" class= "hide">
	<img src="/figure/GID24/GID24studyarea.png" width="800px">
        </div>
        <div id="thirdPage" class = "hide">
	<p style="margin-top:  7px">The code for Dynamic Pseudo-label Assignment is available here:</p>
        <li style="margin-top: 9px" class = "dot"><span class = "lin">Link: <a href="https://github.com/x-ytong/DPA"><b>DPA</b></a> </span></li>
	<p style="margin-top: 15px">Test images covering densely labeled areas for Chinese megacities can be downloaded from:</p>
	<li style="margin-top: 9px" class = "dot"><span class = "lin">Link: <a href="https://whueducn-my.sharepoint.com/:f:/g/personal/xinyi_tong_whu_edu_cn/EhbYkqOuiBtElRn8K1RZ8dUBnL3_FkMPTOqq3zCCJ03Gfg?e=P6xiJL"><b>Onedrive</b></a></span></li>
        <li style="margin-top: 6px" class = "dot"><span class = "lin">Link: <a href="https://pan.baidu.com/s/1tlb5Q7wD2-lUxOx1vfMc4w"><b>Baidudrive</b></a> (extraction code: MGCT)</span></li>
        </div>
</div>

<h4 class = "bar">Result Demonstration</h4>
<p style="margin-top: 21px">Due to the large size of resulting maps, only the central area of each city is shown.</p>
	<hr></hr> 
	<table align="center"><tr>
	<td style="text-align:center"><a href="https://x-ytong.github.io/project/page/Five-Billion-Pixels_beijing.html">  <img src="/figure/GID24/GID24beijingsmall.png"   style="height:168px"></a> <br> Beijing   </td>
	<td style="text-align:center"><a href="https://x-ytong.github.io/project/page/Five-Billion-Pixels_chengdu.html">  <img src="/figure/GID24/GID24chengdusmall.png"   style="height:168px"></a> <br> Chengdu   </td>
	<td style="text-align:center"><a href="https://x-ytong.github.io/project/page/Five-Billion-Pixels_guangzhou.html"><img src="/figure/GID24/GID24guangzhousmall.png" style="height:168px"></a> <br> Guangzhou </td>
	<td style="text-align:center"><a href="https://x-ytong.github.io/project/page/Five-Billion-Pixels_shanghai.html"> <img src="/figure/GID24/GID24shanghaismall.png"  style="height:168px"></a> <br> Shanghai  </td>
	<td style="text-align:center"><a href="https://x-ytong.github.io/project/page/Five-Billion-Pixels_wuhan.html">    <img src="/figure/GID24/GID24wuhansmall.png"     style="height:168px"></a> <br> Wuhan     </td>
	</tr></table>
	<hr></hr>
<p style="margin-top: 21px">Comparison with Google's <a href="https://dynamicworld.app/"><b>Dynamic World</b></a> and ESA's 
<a href="https://esa-worldcover.org/"><b>World Cover</b></a> in Beijing and Guangzhou (all use <b>ST-2</b>).</p>
<hr></hr>
<a href="https://x-ytong.github.io/project/page/Five-Billion-Pixels_comparison.html"><img src="/figure/GID24/GID24comparison.png" width="800px"></a>
<p>(a-b) Land cover map of central area of Beijing from Dynamic World and World Cover. (c) Our result of Beijing. (d-e) Land cover map of central 
area of Guangzhou from Dynamic World and World Cover. (f) Our result of Guangzhou.</p>
<hr></hr>
<div style="border: 11px solid #FFFFFF"></div>

<h3>Citation</h3>
<pre>
@article{FBP2023,
  title={Enabling country-scale land cover mapping with meter-resolution satellite imagery},
  author={Tong, Xin-Yi and Xia, Gui-Song and Zhu, Xiao Xiang},
  journal={ISPRS Journal of Photogrammetry and Remote Sensing},
  volume={196},
  pages={178-196},
  year={2023}
}
</pre>

<h3 style="margin-top: 51px">Contact</h3>
<p>E-mail: xinyi.tong@tum.de</p>
<p>Personal page: <a href="https://x-ytong.github.io/"><b>Xin-Yi Tong</b></a></p>

<div style="border:40px solid #FFFFFF"></div>


</body>
</html>
